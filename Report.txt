DS Challenge report:
For Project Manager:

Problem description:
We are receiving receipt image processing information from third party. We are trying to understand what data is more important to match the receipt with transaction data.
We wanted to sort the matching receipt data where most matched records will be on top and then least matched records.

Solution:
We  are using some sample data to build the model. We have invoice_receipt_match data, having both matched and non matched records.
First of all we will label or classify our data as matched records and non matched records. 
Once we have labeled data we will try to analyse the data fields/columns how records are matched, what data we have for matched records.
We can do this by building program /model and train that with our 80% data and once it trained we can test the model on rest of the 20% data.
We got 96% accuracy score for the model  and so we can list the most important columns/features we should focus while getting information from third party.
Below is the list of datapoints by most important order
1.DateMappingMatch
2.DescriptionMatch
3.PredictedAmountMatch
4.TimeMappingMatch
5.ShortNameMatch
6.PredictedNameMatch
7.PredictedTimeCloseMatch
8.AmountMappingMatch
9.DifferentPredictedDate
10.DifferentPredictedTime

Next for sorting the data in most matching order, we will again build the model and test it on whole dataset.
We calculated predicted probability of receipt_match for each record.
Finally we have sorted the dataset on probabilty by grouping receipt_id and company_id.

For DS team:

Here I have used Python Jupyter Notebook to solve this challenge.
Python Version :Python 3.7.6 (!python -V) 
Jupyter Notebook : 6.0.3
Packages/Liabraries used:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
from sklearn import metrics
from sklearn.model_selection import train_test_split
import pandas_profiling

Coding Style: I have added a comment before each step to show the purpose.

Also I ran one command at a time to display the output of each step/command,instead of creating functions.
But we can create different functions using def. e.g.

def import_data(csv_fileName)
  data_df = pd.read_csv(csv_fileName, delimiter=':')
  return data_df
we can call this function later in main() function or whereever we need to read input data, we need to pass the parameter csvfile with path and inputfile name

e.g. data = import_data('./tide-receipt-matching-challenge/data.csv')

Steps followed to resolve this challenge

Understand the problem: we want to build a model to learn which matching features are the most successful. Produce a trained model which can be used to order a set of transactions by likelihood of matching a receipt image.

Imported the python libraries to import and explore the data

Imported the data csv Data has ':' as a delimeter so need to use delimeter value in read_csv function.

Explore the data, we found out that this is the supervised classification problem and we have labled data with bollean value ( yes/no) so we need to use Logistic regression to build the model.

We added labeled column to classify dataset ( Matched receipt/ Not matched receipt)

We checked the correlation by using df.corr()

Defined the feature columns and non feature columns.

Created subsets of dataset a.with only featured columns b. with target/labels column.

performed data split by using train_test_split() with test size 0.2 means 20%. 10.Imported the Logistic regression model and fit the model on train dataset. 11.Tested teh odel on test data and predicted the result.

We calculated the model accuacyscore,classification report and predicated probability.

We found out the most important features as below 1.DateMappingMatch 2.DescriptionMatch 3.PredictedAmountMatch 4.TimeMappingMatch 5.ShortNameMatch 6.PredictedNameMatch 7.PredictedTimeCloseMatch 8.AmountMappingMatch 9.DifferentPredictedDate 10.DifferentPredictedTime

Next we wanted to sort the invoice_receipt data by the matching order. So I tried to use whole dataset to build a model and to calcuate the predicted probability for whole dataset.

merged te probability result into original dataset.

Sorted (desc)the data on 'pred_probability' value grouped by receipt_id and company_id.
